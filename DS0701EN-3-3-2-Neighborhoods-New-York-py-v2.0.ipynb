{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Segmenting and Clustering Neighborhoods in New York City</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you will learn how to convert addresses into their equivalent latitude and longitude values. Also, you will use the Foursquare API to explore neighborhoods in New York City. You will use the **explore** function to get the most common venue categories in each neighborhood, and then use this feature to group the neighborhoods into clusters. You will use the _k_-means clustering algorithm to complete this task. Finally, you will use the Folium library to visualize the neighborhoods in New York City and their emerging clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "1.  <a href=\"#item1\">Download and Explore Dataset</a>\n",
    "\n",
    "2.  <a href=\"#item2\">Explore Neighborhoods in New York City</a>\n",
    "\n",
    "3.  <a href=\"#item3\">Analyze Each Neighborhood</a>\n",
    "\n",
    "4.  <a href=\"#item4\">Cluster Neighborhoods</a>\n",
    "\n",
    "5.  <a href=\"#item5\">Examine Clusters</a>  \n",
    "    </font>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get the data and start exploring it, let's download all the dependencies that we will need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\karthikn\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - geopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-2020.07  |           py38_0           6 KB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::anaconda==2020.11=py38_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/win-64::bokeh==2.2.3=py38_0\n",
      "  - defaults/noarch::dask==2.30.0=py_0\n",
      "  - defaults/win-64::distributed==2.30.1=py38haa95532_0\n",
      "  - defaults/win-64::ipykernel==5.3.4=py38h5ca1d4c_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_1\n",
      "  - defaults/win-64::jupyter==1.0.0=py38_7\n",
      "  - defaults/noarch::jupyter_client==6.1.7=py_0\n",
      "  - defaults/noarch::jupyter_console==6.2.0=py_0\n",
      "  - defaults/win-64::matplotlib==3.3.2=0\n",
      "  - defaults/win-64::matplotlib-base==3.3.2=py38hba9282a_0\n",
      "  - defaults/noarch::nbclient==0.5.1=py_0\n",
      "  - defaults/win-64::nbconvert==6.0.7=py38_0\n",
      "  - defaults/win-64::notebook==6.1.4=py38_0\n",
      "  - defaults/noarch::qtconsole==4.7.7=py_0\n",
      "  - defaults/win-64::scikit-image==0.17.2=py38h1e1f486_0\n",
      "  - defaults/noarch::seaborn==0.11.0=py_0\n",
      "  - defaults/win-64::spyder==4.1.5=py38_0\n",
      "  - defaults/win-64::spyder-kernels==1.9.4=py38_0\n",
      "  - defaults/win-64::terminado==0.9.1=py38_0\n",
      "  - defaults/win-64::widgetsnbextension==3.5.1=py38_0\n",
      "  - defaults/win-64::_ipyw_jlab_nb_ext_conf==0.1.0=py38_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    anaconda-custom            |           py38_1          36 KB\n",
      "    anyio-2.0.2                |   py38haa244fe_4         111 KB  conda-forge\n",
      "    ca-certificates-2020.12.5  |       h5b45459_0         173 KB  conda-forge\n",
      "    certifi-2020.12.5          |   py38haa244fe_1         144 KB  conda-forge\n",
      "    geographiclib-1.50         |             py_0          34 KB  conda-forge\n",
      "    geopy-2.1.0                |     pyhd3deb0d_0          64 KB  conda-forge\n",
      "    gmpy2-2.1.0b1              |   py38hb63f22f_1         192 KB  conda-forge\n",
      "    jupyter_server-1.2.2       |   py38haa244fe_1         256 KB  conda-forge\n",
      "    jupyterlab-3.0.5           |     pyhd8ed1ab_0         5.7 MB  conda-forge\n",
      "    jupyterlab_server-2.1.3    |     pyhd8ed1ab_0          37 KB  conda-forge\n",
      "    libllvm9-9.0.1             |       hab3b255_3          48 KB  conda-forge\n",
      "    mpc-1.1.0                  |    h7edee0f_1009         322 KB  conda-forge\n",
      "    mpfr-4.0.2                 |       h62dcd97_1         1.9 MB  conda-forge\n",
      "    mpir-3.0.0                 |    he025d50_1002         3.0 MB  conda-forge\n",
      "    nbclassic-0.2.6            |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    openssl-1.1.1i             |       h8ffe710_0         5.8 MB  conda-forge\n",
      "    snappy-1.1.8               |       ha925a31_3          50 KB  conda-forge\n",
      "    sniffio-1.2.0              |   py38haa244fe_1          15 KB  conda-forge\n",
      "    tbb-2020.2                 |       h2d74725_3         175 KB  conda-forge\n",
      "    tornado-6.1                |   py38h294d835_1         649 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        18.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/win-64::_anaconda_depends-2020.07-py38_0\n",
      "  anyio              conda-forge/win-64::anyio-2.0.2-py38haa244fe_4\n",
      "  geographiclib      conda-forge/noarch::geographiclib-1.50-py_0\n",
      "  geopy              conda-forge/noarch::geopy-2.1.0-pyhd3deb0d_0\n",
      "  gmpy2              conda-forge/win-64::gmpy2-2.1.0b1-py38hb63f22f_1\n",
      "  jupyter_server     conda-forge/win-64::jupyter_server-1.2.2-py38haa244fe_1\n",
      "  jupyterlab         conda-forge/noarch::jupyterlab-3.0.5-pyhd8ed1ab_0\n",
      "  jupyterlab_server  conda-forge/noarch::jupyterlab_server-2.1.3-pyhd8ed1ab_0\n",
      "  libllvm9           conda-forge/win-64::libllvm9-9.0.1-hab3b255_3\n",
      "  mpc                conda-forge/win-64::mpc-1.1.0-h7edee0f_1009\n",
      "  mpfr               conda-forge/win-64::mpfr-4.0.2-h62dcd97_1\n",
      "  mpir               conda-forge/win-64::mpir-3.0.0-he025d50_1002\n",
      "  nbclassic          conda-forge/noarch::nbclassic-0.2.6-pyhd8ed1ab_0\n",
      "  scikit-learn       pkgs/main/win-64::scikit-learn-0.23.2-py38h47e9c7a_0\n",
      "  snappy             conda-forge/win-64::snappy-1.1.8-ha925a31_3\n",
      "  sniffio            conda-forge/win-64::sniffio-1.2.0-py38haa244fe_1\n",
      "  tbb                conda-forge/win-64::tbb-2020.2-h2d74725_3\n",
      "  tornado            conda-forge/win-64::tornado-6.1-py38h294d835_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2020.10.14~ --> conda-forge::ca-certificates-2020.12.5-h5b45459_0\n",
      "  certifi            pkgs/main/noarch::certifi-2020.6.20-p~ --> conda-forge/win-64::certifi-2020.12.5-py38haa244fe_1\n",
      "  openssl                                 1.1.1h-he774522_0 --> 1.1.1i-h8ffe710_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                                   2020.11-py38_0 --> custom-py38_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "tornado-6.1          | 649 KB    |            |   0% \n",
      "tornado-6.1          | 649 KB    | 2          |   2% \n",
      "tornado-6.1          | 649 KB    | #7         |  17% \n",
      "tornado-6.1          | 649 KB    | ##9        |  30% \n",
      "tornado-6.1          | 649 KB    | #####1     |  52% \n",
      "tornado-6.1          | 649 KB    | #######8   |  79% \n",
      "tornado-6.1          | 649 KB    | #########3 |  94% \n",
      "tornado-6.1          | 649 KB    | ########## | 100% \n",
      "\n",
      "geographiclib-1.50   | 34 KB     |            |   0% \n",
      "geographiclib-1.50   | 34 KB     | ####7      |  47% \n",
      "geographiclib-1.50   | 34 KB     | ########## | 100% \n",
      "geographiclib-1.50   | 34 KB     | ########## | 100% \n",
      "\n",
      "libllvm9-9.0.1       | 48 KB     |            |   0% \n",
      "libllvm9-9.0.1       | 48 KB     | ###3       |  33% \n",
      "libllvm9-9.0.1       | 48 KB     | ########## | 100% \n",
      "\n",
      "openssl-1.1.1i       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1i       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1i       | 5.8 MB    | 2          |   3% \n",
      "openssl-1.1.1i       | 5.8 MB    | 4          |   5% \n",
      "openssl-1.1.1i       | 5.8 MB    | 7          |   7% \n",
      "openssl-1.1.1i       | 5.8 MB    | 9          |   9% \n",
      "openssl-1.1.1i       | 5.8 MB    | #1         |  11% \n",
      "openssl-1.1.1i       | 5.8 MB    | #3         |  13% \n",
      "openssl-1.1.1i       | 5.8 MB    | #5         |  15% \n",
      "openssl-1.1.1i       | 5.8 MB    | #7         |  17% \n",
      "openssl-1.1.1i       | 5.8 MB    | #9         |  19% \n",
      "openssl-1.1.1i       | 5.8 MB    | ##1        |  21% \n",
      "openssl-1.1.1i       | 5.8 MB    | ##3        |  23% \n",
      "openssl-1.1.1i       | 5.8 MB    | ##5        |  26% \n",
      "openssl-1.1.1i       | 5.8 MB    | ##7        |  28% \n",
      "openssl-1.1.1i       | 5.8 MB    | ##9        |  30% \n",
      "openssl-1.1.1i       | 5.8 MB    | ###1       |  32% \n",
      "openssl-1.1.1i       | 5.8 MB    | ###3       |  34% \n",
      "openssl-1.1.1i       | 5.8 MB    | ###5       |  36% \n",
      "openssl-1.1.1i       | 5.8 MB    | ###7       |  38% \n",
      "openssl-1.1.1i       | 5.8 MB    | ###9       |  40% \n",
      "openssl-1.1.1i       | 5.8 MB    | ####1      |  42% \n",
      "openssl-1.1.1i       | 5.8 MB    | ####4      |  44% \n",
      "openssl-1.1.1i       | 5.8 MB    | ####6      |  47% \n",
      "openssl-1.1.1i       | 5.8 MB    | #####1     |  51% \n",
      "openssl-1.1.1i       | 5.8 MB    | #####4     |  54% \n",
      "openssl-1.1.1i       | 5.8 MB    | #####6     |  57% \n",
      "openssl-1.1.1i       | 5.8 MB    | #####9     |  59% \n",
      "openssl-1.1.1i       | 5.8 MB    | ######1    |  61% \n",
      "openssl-1.1.1i       | 5.8 MB    | ######3    |  64% \n",
      "openssl-1.1.1i       | 5.8 MB    | ######5    |  66% \n",
      "openssl-1.1.1i       | 5.8 MB    | ######7    |  68% \n",
      "openssl-1.1.1i       | 5.8 MB    | #######    |  70% \n",
      "openssl-1.1.1i       | 5.8 MB    | #######2   |  72% \n",
      "openssl-1.1.1i       | 5.8 MB    | #######4   |  74% \n",
      "openssl-1.1.1i       | 5.8 MB    | #######6   |  77% \n",
      "openssl-1.1.1i       | 5.8 MB    | #######8   |  79% \n",
      "openssl-1.1.1i       | 5.8 MB    | ########   |  81% \n",
      "openssl-1.1.1i       | 5.8 MB    | ########3  |  83% \n",
      "openssl-1.1.1i       | 5.8 MB    | ########5  |  86% \n",
      "openssl-1.1.1i       | 5.8 MB    | ########7  |  88% \n",
      "openssl-1.1.1i       | 5.8 MB    | ########9  |  90% \n",
      "openssl-1.1.1i       | 5.8 MB    | #########2 |  92% \n",
      "openssl-1.1.1i       | 5.8 MB    | #########4 |  94% \n",
      "openssl-1.1.1i       | 5.8 MB    | #########6 |  97% \n",
      "openssl-1.1.1i       | 5.8 MB    | #########8 |  99% \n",
      "openssl-1.1.1i       | 5.8 MB    | ########## | 100% \n",
      "\n",
      "geopy-2.1.0          | 64 KB     |            |   0% \n",
      "geopy-2.1.0          | 64 KB     | ##5        |  25% \n",
      "geopy-2.1.0          | 64 KB     | ########## | 100% \n",
      "geopy-2.1.0          | 64 KB     | ########## | 100% \n",
      "\n",
      "snappy-1.1.8         | 50 KB     |            |   0% \n",
      "snappy-1.1.8         | 50 KB     | ###1       |  32% \n",
      "snappy-1.1.8         | 50 KB     | ########## | 100% \n",
      "snappy-1.1.8         | 50 KB     | ########## | 100% \n",
      "\n",
      "gmpy2-2.1.0b1        | 192 KB    |            |   0% \n",
      "gmpy2-2.1.0b1        | 192 KB    | 8          |   8% \n",
      "gmpy2-2.1.0b1        | 192 KB    | #######5   |  75% \n",
      "gmpy2-2.1.0b1        | 192 KB    | ########## | 100% \n",
      "gmpy2-2.1.0b1        | 192 KB    | ########## | 100% \n",
      "\n",
      "mpfr-4.0.2           | 1.9 MB    |            |   0% \n",
      "mpfr-4.0.2           | 1.9 MB    |            |   1% \n",
      "mpfr-4.0.2           | 1.9 MB    | 7          |   7% \n",
      "mpfr-4.0.2           | 1.9 MB    | #3         |  13% \n",
      "mpfr-4.0.2           | 1.9 MB    | #9         |  20% \n",
      "mpfr-4.0.2           | 1.9 MB    | ##6        |  26% \n",
      "mpfr-4.0.2           | 1.9 MB    | ###1       |  31% \n",
      "mpfr-4.0.2           | 1.9 MB    | ####2      |  43% \n",
      "mpfr-4.0.2           | 1.9 MB    | ####9      |  49% \n",
      "mpfr-4.0.2           | 1.9 MB    | #####5     |  56% \n",
      "mpfr-4.0.2           | 1.9 MB    | ######2    |  63% \n",
      "mpfr-4.0.2           | 1.9 MB    | ######9    |  69% \n",
      "mpfr-4.0.2           | 1.9 MB    | #######5   |  76% \n",
      "mpfr-4.0.2           | 1.9 MB    | ########3  |  83% \n",
      "mpfr-4.0.2           | 1.9 MB    | ########9  |  90% \n",
      "mpfr-4.0.2           | 1.9 MB    | #########7 |  97% \n",
      "mpfr-4.0.2           | 1.9 MB    | ########## | 100% \n",
      "\n",
      "sniffio-1.2.0        | 15 KB     |            |   0% \n",
      "sniffio-1.2.0        | 15 KB     | ########## | 100% \n",
      "sniffio-1.2.0        | 15 KB     | ########## | 100% \n",
      "\n",
      "anyio-2.0.2          | 111 KB    |            |   0% \n",
      "anyio-2.0.2          | 111 KB    | #4         |  14% \n",
      "anyio-2.0.2          | 111 KB    | ########## | 100% \n",
      "anyio-2.0.2          | 111 KB    | ########## | 100% \n",
      "\n",
      "jupyterlab_server-2. | 37 KB     |            |   0% \n",
      "jupyterlab_server-2. | 37 KB     | ####3      |  43% \n",
      "jupyterlab_server-2. | 37 KB     | ########## | 100% \n",
      "jupyterlab_server-2. | 37 KB     | ########## | 100% \n",
      "\n",
      "jupyter_server-1.2.2 | 256 KB    |            |   0% \n",
      "jupyter_server-1.2.2 | 256 KB    | 6          |   6% \n",
      "jupyter_server-1.2.2 | 256 KB    | ########7  |  87% \n",
      "jupyter_server-1.2.2 | 256 KB    | ########## | 100% \n",
      "\n",
      "anaconda-custom      | 36 KB     |            |   0% \n",
      "anaconda-custom      | 36 KB     | ####4      |  45% \n",
      "anaconda-custom      | 36 KB     | ########## | 100% \n",
      "anaconda-custom      | 36 KB     | ########## | 100% \n",
      "\n",
      "mpc-1.1.0            | 322 KB    |            |   0% \n",
      "mpc-1.1.0            | 322 KB    | 4          |   5% \n",
      "mpc-1.1.0            | 322 KB    | #####4     |  55% \n",
      "mpc-1.1.0            | 322 KB    | ########## | 100% \n",
      "mpc-1.1.0            | 322 KB    | ########## | 100% \n",
      "\n",
      "nbclassic-0.2.6      | 17 KB     |            |   0% \n",
      "nbclassic-0.2.6      | 17 KB     | #########3 |  93% \n",
      "nbclassic-0.2.6      | 17 KB     | ########## | 100% \n",
      "\n",
      "mpir-3.0.0           | 3.0 MB    |            |   0% \n",
      "mpir-3.0.0           | 3.0 MB    |            |   1% \n",
      "mpir-3.0.0           | 3.0 MB    | 3          |   4% \n",
      "mpir-3.0.0           | 3.0 MB    | 8          |   8% \n",
      "mpir-3.0.0           | 3.0 MB    | #1         |  12% \n",
      "mpir-3.0.0           | 3.0 MB    | ##3        |  23% \n",
      "mpir-3.0.0           | 3.0 MB    | ##7        |  28% \n",
      "mpir-3.0.0           | 3.0 MB    | ###2       |  33% \n",
      "mpir-3.0.0           | 3.0 MB    | ###7       |  37% \n",
      "mpir-3.0.0           | 3.0 MB    | ####2      |  42% \n",
      "mpir-3.0.0           | 3.0 MB    | ####6      |  47% \n",
      "mpir-3.0.0           | 3.0 MB    | #####1     |  51% \n",
      "mpir-3.0.0           | 3.0 MB    | #####5     |  56% \n",
      "mpir-3.0.0           | 3.0 MB    | #####9     |  60% \n",
      "mpir-3.0.0           | 3.0 MB    | #######1   |  72% \n",
      "mpir-3.0.0           | 3.0 MB    | #######7   |  77% \n",
      "mpir-3.0.0           | 3.0 MB    | ########1  |  81% \n",
      "mpir-3.0.0           | 3.0 MB    | ########5  |  86% \n",
      "mpir-3.0.0           | 3.0 MB    | ########9  |  89% \n",
      "mpir-3.0.0           | 3.0 MB    | #########2 |  92% \n",
      "mpir-3.0.0           | 3.0 MB    | #########6 |  96% \n",
      "mpir-3.0.0           | 3.0 MB    | ########## | 100% \n",
      "mpir-3.0.0           | 3.0 MB    | ########## | 100% \n",
      "\n",
      "tbb-2020.2           | 175 KB    |            |   0% \n",
      "tbb-2020.2           | 175 KB    | 9          |   9% \n",
      "tbb-2020.2           | 175 KB    | ########2  |  82% \n",
      "tbb-2020.2           | 175 KB    | ########## | 100% \n",
      "\n",
      "_anaconda_depends-20 | 6 KB      |            |   0% \n",
      "_anaconda_depends-20 | 6 KB      | ########## | 100% \n",
      "_anaconda_depends-20 | 6 KB      | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 173 KB    |            |   0% \n",
      "ca-certificates-2020 | 173 KB    | 9          |   9% \n",
      "ca-certificates-2020 | 173 KB    | ########## | 100% \n",
      "ca-certificates-2020 | 173 KB    | ########## | 100% \n",
      "\n",
      "jupyterlab-3.0.5     | 5.7 MB    |            |   0% \n",
      "jupyterlab-3.0.5     | 5.7 MB    |            |   0% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | 3          |   3% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | 5          |   5% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | 7          |   8% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #          |  10% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #1         |  12% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #8         |  18% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ##1        |  21% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ##4        |  24% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ##7        |  27% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ##9        |  30% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ###2       |  32% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ###4       |  35% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ###7       |  37% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ####       |  40% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ####2      |  43% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ####4      |  45% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ####6      |  47% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ####9      |  49% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #####1     |  51% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #####3     |  54% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #####5     |  55% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #####7     |  58% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #####9     |  60% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ######1    |  62% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ######3    |  64% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ######5    |  66% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ######8    |  68% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #######    |  70% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #######2   |  73% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #######5   |  75% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #######7   |  78% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #######9   |  80% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ########5  |  85% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ########8  |  88% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #########1 |  91% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #########3 |  94% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #########5 |  96% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | #########7 |  98% \n",
      "jupyterlab-3.0.5     | 5.7 MB    | ########## | 100% \n",
      "\n",
      "certifi-2020.12.5    | 144 KB    |            |   0% \n",
      "certifi-2020.12.5    | 144 KB    | #1         |  11% \n",
      "certifi-2020.12.5    | 144 KB    | ######6    |  67% \n",
      "certifi-2020.12.5    | 144 KB    | ########## | 100% \n",
      "certifi-2020.12.5    | 144 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge geopy --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "# uncomment this line if you haven't completed the Foursquare API lab\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item1'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Explore Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neighborhood has a total of 5 boroughs and 306 neighborhoods. In order to segement the neighborhoods and explore them, we will essentially need a dataset that contains the 5 boroughs and the neighborhoods that exist in each borough as well as the the latitude and logitude coordinates of each neighborhood. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience, I downloaded the files and placed it on the server, so you can simply run a `wget` command and access the data. So let's go ahead and do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget -q -O 'newyork_data.json' https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/labs/newyork_data.json\n",
    "print('Data downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and explore the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newyork_data.json') as json_data:\n",
    "    newyork_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newyork_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all the relevant data is in the _features_ key, which is basically a list of the neighborhoods. So, let's define a new variable that includes this data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_data = newyork_data['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first item in this list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tranform the data into a _pandas_ dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is essentially transforming this data of nested Python dictionaries into a _pandas_ dataframe. So let's start by creating an empty dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataframe columns\n",
    "column_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n",
    "\n",
    "# instantiate the dataframe\n",
    "neighborhoods = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the empty dataframe to confirm that the columns are as intended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's loop through the data and fill the dataframe one row at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in neighborhoods_data:\n",
    "    borough = neighborhood_name = data['properties']['borough'] \n",
    "    neighborhood_name = data['properties']['name']\n",
    "        \n",
    "    neighborhood_latlon = data['geometry']['coordinates']\n",
    "    neighborhood_lat = neighborhood_latlon[1]\n",
    "    neighborhood_lon = neighborhood_latlon[0]\n",
    "    \n",
    "    neighborhoods = neighborhoods.append({'Borough': borough,\n",
    "                                          'Neighborhood': neighborhood_name,\n",
    "                                          'Latitude': neighborhood_lat,\n",
    "                                          'Longitude': neighborhood_lon}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly examine the resulting dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make sure that the dataset has all 5 boroughs and 306 neighborhoods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataframe has {} boroughs and {} neighborhoods.'.format(\n",
    "        len(neighborhoods['Borough'].unique()),\n",
    "        neighborhoods.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use geopy library to get the latitude and longitude values of New York City.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define an instance of the geocoder, we need to define a user_agent. We will name our agent <em>ny_explorer</em>, as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "address = 'New York City, NY'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of New York City are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a map of New York with neighborhoods superimposed on top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of New York using latitude and longitude values\n",
    "map_newyork = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(neighborhoods['Latitude'], neighborhoods['Longitude'], neighborhoods['Borough'], neighborhoods['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_newyork)  \n",
    "    \n",
    "map_newyork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folium** is a great visualization library. Feel free to zoom into the above map, and click on each circle mark to reveal the name of the neighborhood and its respective borough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for illustration purposes, let's simplify the above map and segment and cluster only the neighborhoods in Manhattan. So let's slice the original dataframe and create a new dataframe of the Manhattan data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_data = neighborhoods[neighborhoods['Borough'] == 'Manhattan'].reset_index(drop=True)\n",
    "manhattan_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the geographical coordinates of Manhattan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Manhattan, NY'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Manhattan are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with all of New York City, let's visualizat Manhattan the neighborhoods in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Manhattan using latitude and longitude values\n",
    "map_manhattan = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(manhattan_data['Latitude'], manhattan_data['Longitude'], manhattan_data['Neighborhood']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_manhattan)  \n",
    "    \n",
    "map_manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to start utilizing the Foursquare API to explore the neighborhoods and segment them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Foursquare Credentials and Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'your-client-ID' # your Foursquare ID\n",
    "CLIENT_SECRET = 'your-client-secret' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 100 # A default Foursquare API limit value\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore the first neighborhood in our dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the neighborhood's name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_data.loc[0, 'Neighborhood']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the neighborhood's latitude and longitude values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_latitude = manhattan_data.loc[0, 'Latitude'] # neighborhood latitude value\n",
    "neighborhood_longitude = manhattan_data.loc[0, 'Longitude'] # neighborhood longitude value\n",
    "\n",
    "neighborhood_name = manhattan_data.loc[0, 'Neighborhood'] # neighborhood name\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n",
    "                                                               neighborhood_latitude, \n",
    "                                                               neighborhood_longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's get the top 100 venues that are in Marble Hill within a radius of 500 meters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the GET request URL. Name your URL **url**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# type your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click **here** for the solution.\n",
    "\n",
    "<!-- The correct answer is:\n",
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "-->\n",
    "\n",
    "<!--\n",
    "radius = 500 # define radius\n",
    "-->\n",
    "\n",
    "<!--\n",
    "\\\\\\\\ # create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    neighborhood_latitude, \n",
    "    neighborhood_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url # display URL\n",
    "--> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the GET request and examine the resutls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Foursquare lab in the previous module, we know that all the information is in the _items_ key. Before we proceed, let's borrow the **get_category_type** function from the Foursquare lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to clean the json and structure it into a _pandas_ dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many venues were returned by Foursquare?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item2'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Neighborhoods in Manhattan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a function to repeat the same process to all the neighborhoods in Manhattan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now write the code to run the above function on each neighborhood and create a new dataframe called _manhattan_venues_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# type your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click **here** for the solution.\n",
    "\n",
    "<!-- The correct answer is:\n",
    "manhattan_venues = getNearbyVenues(names=manhattan_data['Neighborhood'],\n",
    "                                   latitudes=manhattan_data['Latitude'],\n",
    "                                   longitudes=manhattan_data['Longitude']\n",
    "                                  )\n",
    "--> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the size of the resulting dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manhattan_venues.shape)\n",
    "manhattan_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many venues were returned for each neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find out how many unique categories can be curated from all the returned venues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(manhattan_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item3'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Each Neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "manhattan_onehot = pd.get_dummies(manhattan_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "manhattan_onehot['Neighborhood'] = manhattan_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [manhattan_onehot.columns[-1]] + list(manhattan_onehot.columns[:-1])\n",
    "manhattan_onehot = manhattan_onehot[fixed_columns]\n",
    "\n",
    "manhattan_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's examine the new dataframe size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_grouped = manhattan_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "manhattan_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's confirm the new size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print each neighborhood along with the top 5 most common venues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in manhattan_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = manhattan_grouped[manhattan_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put that into a _pandas_ dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to sort the venues in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the new dataframe and display the top 10 venues for each neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = manhattan_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(manhattan_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(manhattan_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item4'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Neighborhoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run _k_-means to cluster the neighborhood into 5 clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 5\n",
    "\n",
    "manhattan_grouped_clustering = manhattan_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(manhattan_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "manhattan_merged = manhattan_data\n",
    "\n",
    "# merge manhattan_grouped with manhattan_data to add latitude/longitude for each neighborhood\n",
    "manhattan_merged = manhattan_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "manhattan_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the resulting clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(manhattan_merged['Latitude'], manhattan_merged['Longitude'], manhattan_merged['Neighborhood'], manhattan_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item5'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories, you can then assign a name to each cluster. I will leave this exercise to you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 0, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 1, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 2, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 3, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 4, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork-21253531&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork-21253531&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ) and [Polong Lin](https://www.linkedin.com/in/polonglin?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork-21253531&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork-21253531&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). I hope you found this lab interesting and educational. Feel free to contact us if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a course on **Coursera** called _Applied Data Science Capstone_. If you accessed this notebook outside the course, you can take this course online by clicking [here](http://cocl.us/DP0701EN_Coursera_Week3_LAB2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By    | Change Description         |\n",
    "| ----------------- | ------- | ------------- | -------------------------- |\n",
    "| 2020-11-26        | 2.0     | Lakshmi Holla | Updated the markdown cells |\n",
    "|                   |         |               |                            |\n",
    "|                   |         |               |                            |\n",
    "\n",
    "## <h3 align=\"center\">  IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
